[
  {
    "id": "continent_pretraining",
    "name": "Pre-training Pangea",
    "type": "continent",
    "description": "The vast foundational landmass where Large Language Models are initially trained on massive datasets, learning the fundamental rules of language and knowledge.",
    "mapCoordinates": "[[10,5], [30,5], [30,25], [10,25]]",
    "visualStyleHints": "ancient_land_with_large_libraries"
  },
  {
    "id": "island_transformer",
    "name": "Transformer Architecture Island",
    "type": "island",
    "description": "A pivotal island where the revolutionary Transformer architecture, the backbone of most modern LLMs, was conceived.",
    "mapCoordinates": "[[15,10], [20,10], [20,15], [15,15]]",
    "visualStyleHints": "island_with_geometric_structures",
    "parentRegionID": "continent_pretraining",
    "relatedConceptsIDs": ["landmark_attention_paper"]
  },
  {
    "id": "landmark_attention_paper",
    "name": "Attention Is All You Need Lighthouse",
    "type": "landmark_paper",
    "description": "The seminal paper that introduced the Transformer model and the concept of self-attention.",
    "details": "Authors: Vaswani et al. Year: 2017. Key finding: Self-attention mechanisms can achieve state-of-the-art results in sequence transduction tasks. URL: https://arxiv.org/abs/1706.03762",
    "mapCoordinates": "[17,12]",
    "parentIslandID": "island_transformer",
    "iconType": "lighthouse",
    "tags": ["transformer", "attention", "foundation"]
  },
  {
    "id": "continent_alignment",
    "name": "Alignment Archipelago",
    "type": "archipelago",
    "description": "A series of islands focused on techniques to align LLMs with human values, preferences, and ethical considerations.",
    "mapCoordinates": "[[35,30], [55,30], [55,50], [35,50]]",
    "visualStyleHints": "islands_with_lighthouses_and_guiding_beacons"
  },
  {
    "id": "island_rlhf",
    "name": "RLHF Island",
    "type": "island",
    "description": "The central island for Reinforcement Learning from Human Feedback, a key technique for aligning LLMs.",
    "mapCoordinates": "[[40,35], [45,35], [45,40], [40,40]]",
    "visualStyleHints": "island_with_training_grounds_and_feedback_loops",
    "parentRegionID": "continent_alignment",
    "relatedConceptsIDs": ["landmark_instructgpt_paper", "island_ppo_port"]
  },
  {
    "id": "landmark_instructgpt_paper",
    "name": "InstructGPT Monument",
    "type": "landmark_paper",
    "description": "A landmark paper detailing how to fine-tune LLMs with human feedback to follow instructions better.",
    "details": "Authors: Ouyang et al. (OpenAI). Year: 2022. Key finding: RLHF significantly improves instruction following and reduces harmful outputs. URL: https://arxiv.org/abs/2203.02155",
    "mapCoordinates": "[42,37]",
    "parentIslandID": "island_rlhf",
    "iconType": "monument",
    "tags": ["rlhf", "alignment", "instruction_following"]
  },
  {
    "id": "continent_reasoning",
    "name": "Reasoning Continent",
    "type": "continent",
    "description": "A large continent dedicated to enhancing the complex reasoning abilities of LLMs.",
    "mapCoordinates": "[[60,10], [80,10], [80,40], [60,40]]",
    "visualStyleHints": "mountainous_terrain_with_observatories"
  },
  {
    "id": "island_cot",
    "name": "Chain-of-Thought Strait",
    "type": "strait",
    "description": "A crucial passage where LLMs learn to perform step-by-step reasoning.",
    "mapCoordinates": "[[65,15], [70,15], [70,20], [65,20]]",
    "visualStyleHints": "narrow_waterway_with_guiding_lights",
    "parentRegionID": "continent_reasoning",
    "relatedConceptsIDs": ["landmark_cot_paper"]
  },
  {
    "id": "landmark_deepseek_r1_model",
    "name": "DeepSeek-R1 Flagship",
    "type": "landmark_model",
    "description": "A powerful open-source reasoning model by DeepSeek AI.",
    "details": "Organization: DeepSeek AI. Year: 2025. Key capability: Advanced reasoning through cold-start RL and specialized training. URL: [Link to DeepSeek-R1 announcement/paper]",
    "mapCoordinates": "[75,30]",
    "parentIslandID": "continent_reasoning",
    "iconType": "flagship_ship",
    "tags": ["reasoning", "rl", "deepseek"]
  }
]